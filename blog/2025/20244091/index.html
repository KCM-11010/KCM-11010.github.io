<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> On Canonicalization in Geometric Deep Learning | Changmin Kang </title> <meta name="author" content="Changmin Kang"> <meta name="description" content="Equivariant neural networks are powerful tools for machine learning tasks involving data with inherent symmetries. Their power stems from their ability to encode known transformations directly into their architecture, providing a strong inductive bias, especially in domains like physics, chemistry, and computer vision. This blog post delves into recent research addressing some of the key challenges that arise when applying these models."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://kcm-11010.github.io/blog/2025/20244091/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "On Canonicalization in Geometric Deep Learning",
            "description": "Equivariant neural networks are powerful tools for machine learning tasks involving data with inherent symmetries. Their power stems from their ability to encode known transformations directly into their architecture, providing a strong inductive bias, especially in domains like physics, chemistry, and computer vision. This blog post delves into recent research addressing some of the key challenges that arise when applying these models.",
            "published": "May 25, 2025",
            "authors": [
              
              {
                "author": "Changmin Kang",
                "authorURL": "",
                "affiliations": [
                  {
                    "name": "KAIST",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Changmin</span> Kang </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/books/">bookshelf</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>On Canonicalization in Geometric Deep Learning</h1> <p>Equivariant neural networks are powerful tools for machine learning tasks involving data with inherent symmetries. Their power stems from their ability to encode known transformations directly into their architecture, providing a strong inductive bias, especially in domains like physics, chemistry, and computer vision. This blog post delves into recent research addressing some of the key challenges that arise when applying these models.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#a-quick-cover-on-invariance-and-equivariance">A quick cover on invariance and equivariance</a> </div> <div> <a href="#achieving-in-equi-variance-from-existing-models">Achieving in(equi)variance from existing models</a> </div> <div> <a href="#limitation-of-can">Limitation of CAN</a> </div> <div> <a href="#other-recent-works">Other recent works</a> </div> <div> <a href="#conclusion">Conclusion</a> </div> </nav> </d-contents> <p>Invariant and equivariant neural networks have become a crucial tool in machine learning, particularly for tasks where data exhibits inherent <em>symmetries</em>. These symmetries, such as rotations or permutations, are mathematical transformations that leave certain properties of the data unchanged. By incorporating these symmetries into the network architecture, the enhanced models offer improved generalization, enhanced data efficiency, and greater interpretability. However, the development of such networks is not without its challenges.</p> <p>We will delve into recent research that addresses some of the key challenges in the field of invariant/equivariant networks and how they are tackled. In particular, we will see how invariance/equivariance could be achieved for existing architectures via ‘averaging’, rather than explicity design them from the scratch. Then, we will see what are the shortcomings of the proposed ‘averaging’ methods and how they are recently revised.</p> <h2 id="a-quick-cover-on-invariance-and-equivariance">A quick cover on invariance and equivariance</h2> <p>In the field of geometric deep learning, the main focus is to design or obtain a network architecture that properly reflects the geometry, or the symmetries within the dataset. Such symmetries typically originate from the structure of the domain underlying the input signals. For instance, consider the image dataset (refer to the following figure by <d-cite key="bronstein2021geometric"></d-cite>). The domain $\Omega$ is a $n$-by-$n$ grid, where $n$ is an integer, and the space of signals $\mathcal{X}(\Omega)$ consists of the signals $x: \Omega \to \mathbb{R}^3$.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-05-25-20244091/DomSig-480.webp 480w,/assets/img/2025-05-25-20244091/DomSig-800.webp 800w,/assets/img/2025-05-25-20244091/DomSig-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/2025-05-25-20244091/DomSig.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p>Assume that the machine learning system operates on signals on some domain $\Omega$, where the space of the signals $\mathcal{X}(\Omega)$ is a Hilbert space, that is, a linear combination and inner product among the signals are available.</p> <p><br></p> <p>Notice that the collection of symmetries satisfies a number of properties: a composition of two symmetries is again a symmetry, and its inverse, which always exists, is also a symmetry. These properties naturally define a group that consists of the symmetries. Formally, a <em>group</em> $G$ is a set equipped with a binary operation <d-footnote>For brevity and following the common notation, we juxtapose the first argument with the second. </d-footnote> $*:G\times G \to G$ satisfying the following axioms: \(\begin{gather*} \text{Associativity}&amp;: (g_1g_2)g_3 = g_1(g_2g_3),\quad \forall g_1, g_2, g_3 \in G.\\ \text{Identity Element}&amp;: \exists e\in G \;\;\text{s.t.}\;\; eg = g = ge,\quad \forall g\in G.\\ \text{Inverse Element}&amp;: \forall g\in G, \exists g^{-1}\in G \;\;\text{s.t.}\;\; gg^{-1} = e = g^{-1}g. \end{gather*}\)</p> <p><br></p> <p>The gist of the introduction of groups $(G,*)$ of symmetry is to study how the group acts on the data. We will first define how the group acts on the domain $\Omega$. The action of the group on the signal space $\mathcal{X}(\Omega)$ would then be naturally obtained. A group $(G,*)$ acts on $\Omega$ by the (left) <em>group action</em> $\cdot : G\times\Omega \to \Omega$ that satisfies \(\begin{gather*} \text{Compatibility}&amp;: (g_1g_2)\cdot\omega = g_1\cdot(g_2\cdot \omega),\quad \forall g_1, g_2 \in G, \omega\in\Omega.\\ \text{Identity Element}&amp;: e_G\cdot\omega = \omega,\quad \forall \omega\in\Omega. \end{gather*}\)</p> <p>An action of $G$ on $\mathcal{X}(\Omega)$ is naturally obtained from that on $\Omega$: \(\begin{equation*} (g.x)(\omega) \triangleq x\left(g^{-1}\cdot\omega\right). \end{equation*}\)</p> <p>As we assumed that the signal space is a Hilbert space, we can represent the action of each symmetry by some (invertible) matrix. Given some vector space $V$, a <em>group representation</em> is a map $\rho: G \to \mathrm{GL}(V)$ that assigns each group element to an invertible matrix and satisfies $\rho(gh) = \rho(g)\rho(h)$, for all $g, h \in G$.</p> <p><br></p> <p>Now we can define the invariance and the equivariance of a function. A function $f:\mathcal{X}(\Omega) \to \mathcal{Y}$ is $G$<strong>-invariant</strong> if, for all $g \in G, x\in\mathcal{X}$, \(f(\rho(g)x) = f(x).\) Similarly, a function $f:\mathcal{X}(\Omega) \to \mathcal{X}(\Omega’)$ is $G$<strong>-equivariant</strong> if, for all $g \in G, x\in\mathcal{X}$, \(f(\rho(g)x) = \rho'(g)f(x),\) where $G$ is assumed to act both on $\mathcal{X}(\Omega)$ and $\mathcal{X}(\Omega’)$, $\rho’$ is the group representation of $\mathcal{X}(\Omega’)$. In words, a function is $G$-invariant if its output remains intact whatever the symmetry in $G$ acted on the input. On the other hand, a function is $G$-equivariant if its output is modified accordingly to the acted symmetry on the input.</p> <hr> <h2 id="achieving-inequivariance-from-existing-models">Achieving in(equi)variance from existing models</h2> <p>This theme supports rendering beautiful math in inline and display modes using <a href="https://www.mathjax.org/" rel="external nofollow noopener" target="_blank">MathJax 3</a> engine. You just need to surround your math expression with <code class="language-plaintext highlighter-rouge">$$</code>, like <code class="language-plaintext highlighter-rouge">$$ E = mc^2 $$</code>. If you leave it inside a paragraph, it will produce an inline expression, just like \(E = mc^2\).</p> <p>In fact, you can also use a single dollar sign <code class="language-plaintext highlighter-rouge">$</code> to create inline formulas, such as <code class="language-plaintext highlighter-rouge">$ E = mc^2 $</code>, which will render as $ E = mc^2 $. This approach provides the same effect during TeX-based compilation, but visually it appears slightly less bold compared to double-dollar signs <code class="language-plaintext highlighter-rouge">$$</code>, making it blend more naturally with surrounding text.</p> <p>To use display mode, again surround your expression with <code class="language-plaintext highlighter-rouge">$$</code> and place it as a separate paragraph. Here is an example:</p> \[\left( \sum_{k=1}^n a_k b_k \right)^2 \leq \left( \sum_{k=1}^n a_k^2 \right) \left( \sum_{k=1}^n b_k^2 \right)\] <p>Note that MathJax 3 is <a href="https://docs.mathjax.org/en/latest/upgrading/whats-new-3.0.html" rel="external nofollow noopener" target="_blank">a major re-write of MathJax</a> that brought a significant improvement to the loading and rendering speed, which is now <a href="http://www.intmath.com/cg5/katex-mathjax-comparison.php" rel="external nofollow noopener" target="_blank">on par with KaTeX</a>.</p> <hr> <h2 id="limitation-of-can">Limitation of CAN</h2> <p>Citations are then used in the article body with the <code class="language-plaintext highlighter-rouge">&lt;d-cite&gt;</code> tag. The key attribute is a reference to the id provided in the bibliography. The key attribute can take multiple ids, separated by commas.</p> <p>The citation is presented inline like this: <d-cite key="gregor2015draw"></d-cite> (a number that displays more information on hover). If you have an appendix, a bibliography is automatically created and populated in it.</p> <p>Distill chose a numerical inline citation style to improve readability of citation dense articles and because many of the benefits of longer citations are obviated by displaying more information on hover. However, we consider it good style to mention author last names if you discuss something at length and it fits into the flow well — the authors are human and it’s nice for them to have the community associate them with their work.</p> <hr> <h2 id="other-recent-works">Other recent works</h2> <p>asdf</p> <hr> <h2 id="conclusion">Conclusion</h2> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/2025-05-25-20244091.bib"></d-bibliography> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Changmin Kang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>